{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a63e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Union, Optional, Tuple\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "# 设置 Tesseract 路径（Windows 用户）\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "# ===========================================================\n",
    "# 常量定义\n",
    "# ===========================================================\n",
    "DATE_PATTERNS = [\n",
    "    r'(\\d{4}[-/]\\d{1,2}[-/]\\d{1,2}[ T]\\d{1,2}:\\d{2}:\\d{2})',\n",
    "    r'(\\d{4}[-/]\\d{1,2}[-/]\\d{1,2}[ T]\\d{1,2}:\\d{2})',\n",
    "    r'(\\d{4}[-/]\\d{1,2}[-/]\\d{1,2})',\n",
    "]\n",
    "\n",
    "CHECK_KEYS = ['game_id', 'uid', 'timezone', 'lang']\n",
    "\n",
    "# ===========================================================\n",
    "# 图像处理函数\n",
    "# ===========================================================\n",
    "def crop_image_to_table(img: Image.Image, config: Dict) -> Image.Image:\n",
    "    \"\"\"裁剪图像到表格区域\"\"\"\n",
    "    bounds = config[\"table_area\"][\"bounds\"]\n",
    "    w, h = img.size\n",
    "    left = int(w * bounds[\"left_ratio\"])\n",
    "    right = int(w * bounds[\"right_ratio\"])\n",
    "    top = int(h * bounds[\"top_ratio\"])\n",
    "    bottom = int(h * bounds[\"bottom_ratio\"])\n",
    "    return img.crop((left, top, right, bottom))\n",
    "\n",
    "\n",
    "def preprocess_image_for_arknights(img: Image.Image) -> Image.Image:\n",
    "    \"\"\"明日方舟图像预处理：将深灰色文字转换为黑色\"\"\"\n",
    "    img_array = np.array(img)\n",
    "    \n",
    "    # 目标颜色：RGB(31,31,31)\n",
    "    target_color = np.array([31, 31, 31])\n",
    "    tolerance = 15\n",
    "    \n",
    "    # 计算颜色差异\n",
    "    color_diff = np.abs(img_array[:, :, :3] - target_color)\n",
    "    mask = np.all(color_diff <= tolerance, axis=2)\n",
    "    \n",
    "    # 将匹配的像素设为黑色\n",
    "    img_array[mask, :3] = [0, 0, 0]\n",
    "    \n",
    "    return Image.fromarray(img_array)\n",
    "\n",
    "\n",
    "# ===========================================================\n",
    "# OCR识别函数\n",
    "# ===========================================================\n",
    "def perform_ocr(img: Image.Image, lang: str = \"chi_sim\") -> Optional[str]:\n",
    "    \"\"\"执行OCR识别\"\"\"\n",
    "    try:\n",
    "        text = pytesseract.image_to_string(img, lang=lang)\n",
    "        print(f\"OCR识别结果:\\n{text}\")\n",
    "        return text.strip() if text else None\n",
    "    except Exception as e:\n",
    "        print(f\"[OCR] 识别失败: {e}\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9d3f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================================\n",
    "# 文本解析函数\n",
    "# ===========================================================\n",
    "def extract_timestamp_from_line(line: str) -> Optional[str]:\n",
    "    \"\"\"从文本行中提取时间戳\"\"\"\n",
    "    for pattern in DATE_PATTERNS:\n",
    "        match = re.search(pattern, line)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "    return None\n",
    "\n",
    "\n",
    "def parse_single_line(line: str, column_indices: Dict) -> Optional[Dict]:\n",
    "    \"\"\"解析单行文本为条目\"\"\"\n",
    "    timestamp = extract_timestamp_from_line(line)\n",
    "    if not timestamp:\n",
    "        return None\n",
    "    \n",
    "    # 查找时间戳位置\n",
    "    ts_match = re.search(re.escape(timestamp), line)\n",
    "    if not ts_match:\n",
    "        return None\n",
    "    \n",
    "    # 提取时间戳前的部分\n",
    "    left_part = line[:ts_match.start()].strip(\" |,-\\t\")\n",
    "    \n",
    "    # 分割字段\n",
    "    if \"|\" in left_part:\n",
    "        parts = [p.strip() for p in left_part.split(\"|\")]\n",
    "    else:\n",
    "        parts = re.split(r\"\\s{2,}\", left_part)\n",
    "    \n",
    "    # 提取条目信息\n",
    "    item = parts[column_indices[\"item\"]].strip() if len(parts) > column_indices[\"item\"] else \"\"\n",
    "    pool = parts[column_indices[\"pool\"]].strip() if len(parts) > column_indices[\"pool\"] else \"\"\n",
    "    \n",
    "    return {\"item\": item, \"pool\": pool, \"time\": timestamp}\n",
    "\n",
    "\n",
    "def parse_ocr_text_to_entries(ocr_text: str, config: Dict) -> List[Dict]:\n",
    "    \"\"\"将OCR文本解析为条目列表\"\"\"\n",
    "    if not ocr_text:\n",
    "        return []\n",
    "    \n",
    "    column_indices = config[\"table_area\"][\"column_indices\"]\n",
    "    lines = [line.strip() for line in ocr_text.splitlines() if line.strip()]\n",
    "    \n",
    "    entries = []\n",
    "    for line in lines:\n",
    "        entry = parse_single_line(line, column_indices)\n",
    "        if entry:\n",
    "            entries.append(entry)\n",
    "    \n",
    "    print(f\"解析到 {len(entries)} 个条目\")\n",
    "    return entries\n",
    "\n",
    "\n",
    "# ==========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a11a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================================\n",
    "# 数据清洗和修正函数\n",
    "# ===========================================================\n",
    "def fix_timestamp_format(ts: str) -> Optional[str]:\n",
    "    \"\"\"修复时间戳格式为标准格式\"\"\"\n",
    "    if not ts:\n",
    "        return None\n",
    "    \n",
    "    # 标准化分隔符\n",
    "    s = ts.strip().replace(\"T\", \" \").replace(\".\", \"-\").replace(\"/\", \"-\")\n",
    "    s = re.sub(r'[年月日]', '-', s)\n",
    "    s = re.sub(r'[^0-9\\- :]', '', s)\n",
    "    \n",
    "    # 尝试多种格式解析\n",
    "    for fmt in DATE_FORMATS:\n",
    "        try:\n",
    "            dt = datetime.strptime(s, fmt)\n",
    "            return dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        except ValueError:\n",
    "            continue\n",
    "    \n",
    "    # 尝试纯数字解析\n",
    "    digits = re.sub(r'\\D', '', s)\n",
    "    if len(digits) >= 14:\n",
    "        try:\n",
    "            dt = datetime.strptime(digits[:14], \"%Y%m%d%H%M%S\")\n",
    "            return dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        except ValueError:\n",
    "            pass\n",
    "    elif len(digits) >= 8:\n",
    "        try:\n",
    "            dt = datetime.strptime(digits[:8], \"%Y%m%d\")\n",
    "            return dt.strftime(\"%Y-%m-%d 00:00:00\")\n",
    "        except ValueError:\n",
    "            pass\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def clean_name_string(name: str, prefix_patterns: List[str], suffix_patterns: List[str]) -> str:\n",
    "    \"\"\"清理名称中的前缀和后缀\"\"\"\n",
    "    cleaned = name\n",
    "    for pattern in prefix_patterns:\n",
    "        cleaned = re.sub(pattern, \"\", cleaned).strip()\n",
    "    for pattern in suffix_patterns:\n",
    "        cleaned = re.sub(pattern, \"\", cleaned).strip()\n",
    "    return cleaned\n",
    "\n",
    "\n",
    "def calculate_edit_distance(s1: str, s2: str) -> int:\n",
    "    \"\"\"计算编辑距离（莱文斯坦距离）\"\"\"\n",
    "    if len(s1) < len(s2):\n",
    "        return calculate_edit_distance(s2, s1)\n",
    "    if len(s2) == 0:\n",
    "        return len(s1)\n",
    "    \n",
    "    previous_row = range(len(s2) + 1)\n",
    "    for i, c1 in enumerate(s1):\n",
    "        current_row = [i + 1]\n",
    "        for j, c2 in enumerate(s2):\n",
    "            insertions = previous_row[j + 1] + 1\n",
    "            deletions = current_row[j] + 1\n",
    "            substitutions = previous_row[j] + (c1 != c2)\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "        previous_row = current_row\n",
    "    \n",
    "    return previous_row[-1]\n",
    "\n",
    "\n",
    "def correct_recognized_name(name: str, valid_names: set, max_distance_ratio: float = 0.5) -> Dict[str, Union[str, bool]]:\n",
    "    \"\"\"纠正识别错误的名称\"\"\"\n",
    "    if name in valid_names:\n",
    "        return {\"name\": name, \"is_valid\": True}\n",
    "    \n",
    "    # 寻找最相似的名称\n",
    "    if not valid_names:\n",
    "        print(f\"[警告] 无法纠正名称 '{name}'：有效名称列表为空\")\n",
    "        return {\"name\": name, \"is_valid\": False}\n",
    "    \n",
    "    best_match = min(valid_names, key=lambda x: calculate_edit_distance(name, x))\n",
    "    distance = calculate_edit_distance(name, best_match)\n",
    "    \n",
    "    if distance <= len(name) * max_distance_ratio:\n",
    "        return {\"name\": best_match, \"is_valid\": True}\n",
    "    \n",
    "    print(f\"[警告] 无法纠正名称: {name}\")\n",
    "    return {\"name\": name, \"is_valid\": False}\n",
    "\n",
    "\n",
    "def clean_and_correct_entry(entry: Dict, valid_items: set, valid_pools: set, \n",
    "                           clean_config: Dict) -> Optional[Dict]:\n",
    "    \"\"\"清洗和修正单个条目\"\"\"\n",
    "    # 清理名称\n",
    "    if clean_config[\"enable_clean_name\"]:\n",
    "        entry[\"item\"] = clean_name_string(entry[\"item\"], \n",
    "                                         clean_config[\"prefix_patterns\"], \n",
    "                                         clean_config[\"suffix_patterns\"])\n",
    "        entry[\"pool\"] = clean_name_string(entry[\"pool\"], \n",
    "                                         clean_config[\"prefix_patterns\"], \n",
    "                                         clean_config[\"suffix_patterns\"])\n",
    "    \n",
    "    # 纠正名称\n",
    "    item_result = correct_recognized_name(entry[\"item\"], valid_items)\n",
    "    pool_result = correct_recognized_name(entry[\"pool\"], valid_pools)\n",
    "    \n",
    "    entry[\"item\"] = item_result[\"name\"]\n",
    "    entry[\"pool\"] = pool_result[\"name\"]\n",
    "    entry[\"is_valid\"] = item_result[\"is_valid\"] and pool_result[\"is_valid\"]\n",
    "    \n",
    "    # 修复时间\n",
    "    entry[\"time\"] = fix_timestamp_format(entry[\"time\"])\n",
    "    \n",
    "    # 跳过无效时间的条目\n",
    "    if not entry[\"time\"]:\n",
    "        print(f\"[警告] 跳过无效时间条目: {entry}\")\n",
    "        return None\n",
    "    \n",
    "    return entry\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "68439f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================================\n",
    "#  工具函数：清理名称前后缀\n",
    "# ===========================================================\n",
    "def clean_name(name: str, prefix_patterns: List[str], suffix_patterns: List[str]) -> str:\n",
    "    \"\"\"\n",
    "    清理名称中的前缀和后缀。\n",
    "    :param name: 原始名称\n",
    "    :param prefix_patterns: 前缀的正则表达式列表\n",
    "    :param suffix_patterns: 后缀的正则表达式列表\n",
    "    :return: 清理后的名称\n",
    "    \"\"\"\n",
    "    for pattern in prefix_patterns:\n",
    "        name = re.sub(pattern, \"\", name).strip()\n",
    "    for pattern in suffix_patterns:\n",
    "        name = re.sub(pattern, \"\", name).strip()\n",
    "    return name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09dfc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================================\n",
    "# 文件合并和兼容性检查\n",
    "# ===========================================================\n",
    "def check_info_compatibility(info1: Dict, info2: Dict) -> bool:\n",
    "    \"\"\"检查两个文件的info字段是否兼容\"\"\"\n",
    "    for key in CHECK_KEYS:\n",
    "        if info1.get(key) != info2.get(key):\n",
    "            print(f\"[警告] 文件的 info 字段 {key} 不一致：{info1.get(key)} vs {info2.get(key)}\")\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def find_compatible_history_files(new_file_path: Path, existing_files: List[Path]) -> List[Path]:\n",
    "    \"\"\"查找与当前文件兼容的历史文件\"\"\"\n",
    "    compatible_files = []\n",
    "    \n",
    "    try:\n",
    "        new_data = load_json_file(new_file_path)\n",
    "        new_info = new_data['info']\n",
    "        \n",
    "        for file_path in existing_files:\n",
    "            try:\n",
    "                old_data = load_json_file(file_path)\n",
    "                if check_info_compatibility(new_info, old_data['info']):\n",
    "                    compatible_files.append(file_path)\n",
    "            except Exception as e:\n",
    "                print(f\"读取文件 {file_path} 失败: {e}\")\n",
    "                continue\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"读取新文件 {new_file_path} 失败: {e}\")\n",
    "    \n",
    "    return compatible_files\n",
    "\n",
    "\n",
    "def get_latest_history_file(files: List[Path]) -> Tuple[Optional[Path], int]:\n",
    "    \"\"\"获取最新的历史文件\"\"\"\n",
    "    if not files:\n",
    "        return None, 0\n",
    "    \n",
    "    latest_file = None\n",
    "    latest_timestamp = 0\n",
    "    \n",
    "    for file_path in files:\n",
    "        try:\n",
    "            data = load_json_file(file_path)\n",
    "            timestamp = data['info']['export_timestamp']\n",
    "            \n",
    "            if timestamp > latest_timestamp:\n",
    "                latest_timestamp = timestamp\n",
    "                latest_file = file_path\n",
    "        except Exception as e:\n",
    "            print(f\"读取文件 {file_path} 失败: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return latest_file, latest_timestamp\n",
    "\n",
    "\n",
    "def find_overlapping_entries(data1: List[Dict], data2: List[Dict]) -> Tuple[int, int, int, int]:\n",
    "    \"\"\"查找两个数据集中的重叠条目\"\"\"\n",
    "    for i in range(len(data1)):\n",
    "        for j in range(len(data2)):\n",
    "            if (data1[i]['time'] == data2[j]['time'] and \n",
    "                data1[i]['pool'] == data2[j]['pool'] and \n",
    "                data1[i]['item'] == data2[j]['item']):\n",
    "                \n",
    "                # 检查连续重叠\n",
    "                k = 0\n",
    "                while (i + k < len(data1) and j + k < len(data2) and \n",
    "                       data1[i + k]['time'] == data2[j + k]['time'] and \n",
    "                       data1[i + k]['pool'] == data2[j + k]['pool'] and \n",
    "                       data1[i + k]['item'] == data2[j + k]['item']):\n",
    "                    k += 1\n",
    "                \n",
    "                if k >= MIN_OVERLAP_COUNT:\n",
    "                    return i, i + k, j, j + k\n",
    "    \n",
    "    return -1, -1, -1, -1\n",
    "\n",
    "\n",
    "def merge_json_files(file1: str, file2: str, output_file: str) -> None:\n",
    "    \"\"\"合并两个JSON文件\"\"\"\n",
    "    # 加载文件\n",
    "    data1 = load_json_file(file1)\n",
    "    data2 = load_json_file(file2)\n",
    "    \n",
    "    # 检查兼容性\n",
    "    if not check_info_compatibility(data1['info'], data2['info']):\n",
    "        raise ValueError(\"两个文件的 info 字段不一致，无法合并\")\n",
    "    \n",
    "    # 使用较晚导出的info\n",
    "    info = data2['info'] if data2['info']['export_timestamp'] > data1['info']['export_timestamp'] else data1['info']\n",
    "    \n",
    "    # 查找重叠\n",
    "    start1, end1, start2, end2 = find_overlapping_entries(data1['data'], data2['data'])\n",
    "    if start1 == -1:\n",
    "        raise ValueError(f\"未找到连续 {MIN_OVERLAP_COUNT} 条以上的重叠条目\")\n",
    "    \n",
    "    # 分割数据\n",
    "    before1 = data1[:start1]\n",
    "    overlap = data1[start1:end1]  # 使用第一个数据集的重叠部分\n",
    "    after1 = data1[end1:]\n",
    "    \n",
    "    before2 = data2[:start2]\n",
    "    after2 = data2[end2:]\n",
    "    \n",
    "    # 选择较长的前后部分\n",
    "    before_merged = before1 if len(before1) > len(before2) else before2\n",
    "    after_merged = after1 if len(after1) > len(after2) else after2\n",
    "    \n",
    "    # 合并数据\n",
    "    merged_data = before_merged + overlap + after_merged\n",
    "    \n",
    "    # 保存合并结果\n",
    "    merged_json = {\"info\": info, \"data\": merged_data}\n",
    "    save_json_file(merged_json, output_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0da0701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================================\n",
    "# 主处理流程函数\n",
    "# ===========================================================\n",
    "def create_output_directory(output_dir: str = \"gacha_history\") -> Path:\n",
    "    \"\"\"创建输出目录\"\"\"\n",
    "    output_folder = Path(output_dir)\n",
    "    output_folder.mkdir(exist_ok=True)\n",
    "    return output_folder\n",
    "\n",
    "\n",
    "def get_image_paths(image_source: Union[str, List[str]]) -> List[str]:\n",
    "    \"\"\"获取所有图像文件路径\"\"\"\n",
    "    if isinstance(image_source, str) and Path(image_source).is_dir():\n",
    "        return [str(p) for p in Path(image_source).rglob(\"*.png\")]\n",
    "    elif isinstance(image_source, str):\n",
    "        return [image_source]\n",
    "    else:\n",
    "        return list(image_source)\n",
    "\n",
    "\n",
    "def process_single_image(image_path: str, config: Dict, clean_config: Dict, \n",
    "                        valid_items: set, valid_pools: set) -> List[Dict]:\n",
    "    \"\"\"处理单张图像\"\"\"\n",
    "    print(f\"处理图像: {Path(image_path).name}\")\n",
    "    \n",
    "    # 图像处理\n",
    "    img = Image.open(image_path)\n",
    "    cropped_img = crop_image_to_table(img, config)\n",
    "    processed_img = preprocess_image_for_arknights(cropped_img)\n",
    "    \n",
    "    # OCR识别\n",
    "    ocr_text = perform_ocr(processed_img)\n",
    "    if not ocr_text:\n",
    "        print(f\"[警告] 图像 {Path(image_path).name} OCR识别失败\")\n",
    "        return []\n",
    "    \n",
    "    # 解析文本\n",
    "    raw_entries = parse_ocr_text_to_entries(ocr_text, config)\n",
    "    \n",
    "    # 清洗和修正\n",
    "    cleaned_entries = []\n",
    "    for entry in raw_entries:\n",
    "        cleaned_entry = clean_and_correct_entry(entry, valid_items, valid_pools, clean_config)\n",
    "        if cleaned_entry:\n",
    "            cleaned_entries.append(cleaned_entry)\n",
    "    \n",
    "    print(f\"从 {Path(image_path).name} 提取到 {len(cleaned_entries)} 个有效条目\")\n",
    "    return cleaned_entries\n",
    "\n",
    "\n",
    "def create_export_data(all_entries: List[Dict], game_id: str, game_name: str, \n",
    "                      uid: str, timezone: int, lang: str) -> Dict:\n",
    "    \"\"\"创建导出数据结构\"\"\"\n",
    "    # 按时间排序（从新到旧）\n",
    "    sorted_entries = sorted(all_entries, key=lambda x: x[\"time\"], reverse=True)\n",
    "    \n",
    "    # 当前时间\n",
    "    export_timestamp = int(datetime.now().timestamp())\n",
    "    \n",
    "    return {\n",
    "        \"info\": {\n",
    "            \"game_id\": game_id,\n",
    "            \"game_name\": game_name,\n",
    "            \"export_timestamp\": export_timestamp,\n",
    "            \"export_app\": \"ocr_export\",\n",
    "            \"export_app_version\": \"v0.0.1\",\n",
    "            \"export_time\": datetime.fromtimestamp(export_timestamp).strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            \"uid\": uid,\n",
    "            \"timezone\": timezone,\n",
    "            \"lang\": lang,\n",
    "            \"total_entries\": len(sorted_entries),\n",
    "        },\n",
    "        \"data\": sorted_entries,\n",
    "    }\n",
    "\n",
    "\n",
    "def save_and_merge_file(export_data: Dict, output_folder: Path, game_id: str) -> Path:\n",
    "    \"\"\"保存文件并尝试与历史文件合并\"\"\"\n",
    "    # 生成文件名\n",
    "    export_time_str = datetime.fromtimestamp(export_data[\"info\"][\"export_timestamp\"]).strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_file = output_folder / f\"{game_id}_{export_time_str}.json\"\n",
    "    \n",
    "    # 保存新文件\n",
    "    save_json_file(export_data, output_file)\n",
    "    print(f\"已创建新文件: {output_file}\")\n",
    "    \n",
    "    # 查找历史文件\n",
    "    existing_files = list(output_folder.glob(f\"{game_id}_*.json\"))\n",
    "    existing_files = [f for f in existing_files if f != output_file]\n",
    "    \n",
    "    if not existing_files:\n",
    "        print(\"未找到历史文件，无需合并\")\n",
    "        return output_file\n",
    "    \n",
    "    print(f\"找到 {len(existing_files)} 个历史文件\")\n",
    "    \n",
    "    # 查找兼容文件\n",
    "    compatible_files = find_compatible_history_files(output_file, existing_files)\n",
    "    print(f\"其中 {len(compatible_files)} 个文件与当前账号兼容\")\n",
    "    \n",
    "    if not compatible_files:\n",
    "        print(\"未找到兼容的历史文件\")\n",
    "        return output_file\n",
    "    \n",
    "    # 获取最新兼容文件\n",
    "    latest_file, latest_timestamp = get_latest_history_file(compatible_files)\n",
    "    if not latest_file:\n",
    "        print(\"未找到有效的兼容文件\")\n",
    "        return output_file\n",
    "    \n",
    "    print(f\"找到最新兼容文件: {latest_file.name} (导出时间: {datetime.fromtimestamp(latest_timestamp).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
    "    \n",
    "    # 尝试合并\n",
    "    try:\n",
    "        print(f\"尝试合并: {latest_file.name} → {output_file.name}\")\n",
    "        merge_json_files(str(latest_file), str(output_file), str(output_file))\n",
    "        print(f\"合并完成，结果已保存到 {output_file}\")\n",
    "        \n",
    "        # 删除旧文件\n",
    "        try:\n",
    "            latest_file.unlink()\n",
    "            print(f\"已删除旧文件: {latest_file.name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[警告] 无法删除旧文件 {latest_file.name}: {e}\")\n",
    "            \n",
    "    except ValueError as e:\n",
    "        print(f\"合并失败: {e}\")\n",
    "        print(f\"保留两个独立文件\")\n",
    "    \n",
    "    return output_file\n",
    "\n",
    "\n",
    "def run_pipeline(\n",
    "    image_source: Union[str, List[str]],\n",
    "    uid: str = \"1234567890\",\n",
    "    timezone: int = 8,\n",
    "    lang: str = \"zh-cn\",\n",
    "    config_path: str = \"game_processing_config_ark.json\",\n",
    "    data_path: str = \"game_name_ark.json\",\n",
    "    output_dir: str = \"gacha_history\"\n",
    ") -> Optional[Path]:\n",
    "    \"\"\"\n",
    "    主处理流程\n",
    "    \n",
    "    Args:\n",
    "        image_source: 图像路径或目录\n",
    "        uid: 用户ID\n",
    "        timezone: 时区\n",
    "        lang: 语言\n",
    "        config_path: 配置文件路径\n",
    "        data_path: 游戏数据文件路径\n",
    "        output_dir: 输出目录\n",
    "        \n",
    "    Returns:\n",
    "        最终保存的文件路径，如果失败则返回None\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"开始处理抽卡记录图像\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        # 加载配置和数据\n",
    "        config = load_config(config_path)\n",
    "        game_data = load_game_data(data_path)\n",
    "        \n",
    "        # 获取配置信息\n",
    "        game_id = config[\"game_info\"][\"game_id\"]\n",
    "        game_name = config[\"game_info\"][\"game_name\"]\n",
    "        \n",
    "        # 有效名称集合\n",
    "        valid_items = set(game_data[\"character\"])\n",
    "        valid_pools = set(game_data[\"pool\"])\n",
    "        \n",
    "        # 清理配置\n",
    "        clean_config = {\n",
    "            \"enable_clean_name\": config[\"text_processing\"][\"enable_clean_name\"],\n",
    "            \"prefix_patterns\": config[\"text_processing\"][\"patterns\"][\"prefix_patterns\"],\n",
    "            \"suffix_patterns\": config[\"text_processing\"][\"patterns\"][\"suffix_patterns\"]\n",
    "        }\n",
    "        \n",
    "        # 创建输出目录\n",
    "        output_folder = create_output_directory(output_dir)\n",
    "        \n",
    "        # 获取图像路径\n",
    "        image_paths = get_image_paths(image_source)\n",
    "        if not image_paths:\n",
    "            print(\"未找到任何图像文件\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"找到 {len(image_paths)} 张图像\")\n",
    "        \n",
    "        # 处理所有图像\n",
    "        all_entries = []\n",
    "        for img_path in image_paths:\n",
    "            entries = process_single_image(img_path, config, clean_config, valid_items, valid_pools)\n",
    "            all_entries.extend(entries)\n",
    "        \n",
    "        if not all_entries:\n",
    "            print(\"未提取到任何有效记录\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"\\n成功提取 {len(all_entries)} 条抽卡记录\")\n",
    "        \n",
    "        # 创建导出数据\n",
    "        export_data = create_export_data(all_entries, game_id, game_name, uid, timezone, lang)\n",
    "        \n",
    "        # 保存并合并文件\n",
    "        final_file = save_and_merge_file(export_data, output_folder, game_id)\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"处理完成\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        return final_file\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[错误] 处理过程中发生异常: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3170e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: \n",
      "以风雪为拆                                  香草                         2025-11-14 11:43:46\n",
      "以风雪为拆                                    芬                          2025-11-13 11:34:56\n",
      "以风雪为拆                                  酸糖                         2025-11-12 10:37:07\n",
      "以风雪为拆                                  验风                         2025-11-11 10:49:29\n",
      "以风雪为拆                                  古米                         2025-11-10 10:56:13\n",
      "以风雪为拆                                 月见夜                       2025-11-10 10:56:13\n",
      "以风雪为拆                                  露托                         2025-11-10 10:56:13\n",
      "以风雪为拆                                  空爆                         2025-11-10 10:56:13\n",
      "以风雪为拆                                 调香师                       2025-11-10 10:56:13\n",
      "以风雪为拆                                  卡强                         2025-11-10 10:56:13\n",
      "\n",
      "\n",
      "entries: [{'item': '香草', 'pool': '以风雪为拆', 'time': '2025-11-14 11:43:46'}, {'item': '芬', 'pool': '以风雪为拆', 'time': '2025-11-13 11:34:56'}, {'item': '酸糖', 'pool': '以风雪为拆', 'time': '2025-11-12 10:37:07'}, {'item': '验风', 'pool': '以风雪为拆', 'time': '2025-11-11 10:49:29'}, {'item': '古米', 'pool': '以风雪为拆', 'time': '2025-11-10 10:56:13'}, {'item': '月见夜', 'pool': '以风雪为拆', 'time': '2025-11-10 10:56:13'}, {'item': '露托', 'pool': '以风雪为拆', 'time': '2025-11-10 10:56:13'}, {'item': '空爆', 'pool': '以风雪为拆', 'time': '2025-11-10 10:56:13'}, {'item': '调香师', 'pool': '以风雪为拆', 'time': '2025-11-10 10:56:13'}, {'item': '卡强', 'pool': '以风雪为拆', 'time': '2025-11-10 10:56:13'}]\n",
      "[Warning] 无法纠正名称: 验风\n",
      "text: \n",
      "空白频段                                    空爆                         2025-10-9 12:00:10\n",
      "空白频段                                  米格鲁                        2025-10-9 12:00:10\n",
      "空白频段                                  休谋斯                        2025-10-9 12:00:10\n",
      "空白频段                                  玫兰莎                        2025-10-9 12:00:10\n",
      "空白频段                                    杜宾                         2025-10-9 11:59:53\n",
      "空白频段                                    空爆                         2025-10-9 11:59:53\n",
      "空白频段                         过NEWI折本                         2025-10-9 11:59:53\n",
      "空白频段                         洁NEWI冬时                         2025-10-9 11:59:53\n",
      "空白频段                                    验风                         2025-10-9 11:59:53\n",
      "空白频段                                  清道夫                        2025-10-9 11:59:53\n",
      "\n",
      "\n",
      "entries: [{'item': '空爆', 'pool': '空白频段', 'time': '2025-10-9 12:00:10'}, {'item': '米格鲁', 'pool': '空白频段', 'time': '2025-10-9 12:00:10'}, {'item': '休谋斯', 'pool': '空白频段', 'time': '2025-10-9 12:00:10'}, {'item': '玫兰莎', 'pool': '空白频段', 'time': '2025-10-9 12:00:10'}, {'item': '杜宾', 'pool': '空白频段', 'time': '2025-10-9 11:59:53'}, {'item': '空爆', 'pool': '空白频段', 'time': '2025-10-9 11:59:53'}, {'item': '过NEWI折本', 'pool': '空白频段', 'time': '2025-10-9 11:59:53'}, {'item': '洁NEWI冬时', 'pool': '空白频段', 'time': '2025-10-9 11:59:53'}, {'item': '验风', 'pool': '空白频段', 'time': '2025-10-9 11:59:53'}, {'item': '清道夫', 'pool': '空白频段', 'time': '2025-10-9 11:59:53'}]\n",
      "[Warning] 无法纠正名称: 休谋斯\n",
      "[Warning] 无法纠正名称: 过I折本\n",
      "[Warning] 无法纠正名称: 验风\n",
      "text: \n",
      "空白频段                                    冬时                         2025-10-9 12:00:17\n",
      "空白频段                                  米格鲁                        2025-10-9 12:00:17\n",
      "空白频段                      二NEWI真言 (6太)                      2025-10-9 12:00:17\n",
      "空白频段                                    倒羽                          2025-10-9 12:00:17\n",
      "空白频段                                    流星                         2025-10-9 12:00:10\n",
      "空白频段                                    松果                         2025-10-9 12:00:10\n",
      "空白频段                                    渡桥                         2025-10-9 12:00:10\n",
      "空白频段                                    铀躁                         2025-10-9 12:00:10\n",
      "空白频段                                    露托                         2025-10-9 12:00:10\n",
      "空白频段                                    空爆                         2025-10-9 12:00:10\n",
      "\n",
      "\n",
      "entries: [{'item': '冬时', 'pool': '空白频段', 'time': '2025-10-9 12:00:17'}, {'item': '米格鲁', 'pool': '空白频段', 'time': '2025-10-9 12:00:17'}, {'item': '二NEWI真言 (6太)', 'pool': '空白频段', 'time': '2025-10-9 12:00:17'}, {'item': '倒羽', 'pool': '空白频段', 'time': '2025-10-9 12:00:17'}, {'item': '流星', 'pool': '空白频段', 'time': '2025-10-9 12:00:10'}, {'item': '松果', 'pool': '空白频段', 'time': '2025-10-9 12:00:10'}, {'item': '渡桥', 'pool': '空白频段', 'time': '2025-10-9 12:00:10'}, {'item': '铀躁', 'pool': '空白频段', 'time': '2025-10-9 12:00:10'}, {'item': '露托', 'pool': '空白频段', 'time': '2025-10-9 12:00:10'}, {'item': '空爆', 'pool': '空白频段', 'time': '2025-10-9 12:00:10'}]\n",
      "[Warning] 无法纠正名称: 倒羽\n",
      "[Warning] 无法纠正名称: 铀躁\n",
      "text: \n",
      "未致蒙尘\n",
      "\n",
      "2025-9-20 10:34:53\n",
      "\n",
      "未致蒙尘                                 罗比车塔                       2025-9-20 10:34:48\n",
      "未致蒙尘                                          障索                              2025-9-20 09:12:22\n",
      "未致蒙尘                                          地有灵                              2025-9-20 09:12:16\n",
      "标准寻访                                    寻澜                         2025-9-11 16:28:00\n",
      "标准寻访                                    古米                         2025-9-11 16:27:55\n",
      "标准寻访                                     芬                           2025-9-11 16:27:51\n",
      "标准寻访                                      兰                         2025-9-11 16:27:47\n",
      "标准寻访                                    验风                         2025-9-11 16:27:41\n",
      "标准寻访                                    斑点                         2025-9-11 16:27:32\n",
      "\n",
      "\n",
      "entries: [{'item': '', 'pool': '', 'time': '2025-9-20 10:34:53'}, {'item': '罗比车塔', 'pool': '未致蒙尘', 'time': '2025-9-20 10:34:48'}, {'item': '障索', 'pool': '未致蒙尘', 'time': '2025-9-20 09:12:22'}, {'item': '地有灵', 'pool': '未致蒙尘', 'time': '2025-9-20 09:12:16'}, {'item': '寻澜', 'pool': '标准寻访', 'time': '2025-9-11 16:28:00'}, {'item': '古米', 'pool': '标准寻访', 'time': '2025-9-11 16:27:55'}, {'item': '芬', 'pool': '标准寻访', 'time': '2025-9-11 16:27:51'}, {'item': '兰', 'pool': '标准寻访', 'time': '2025-9-11 16:27:47'}, {'item': '验风', 'pool': '标准寻访', 'time': '2025-9-11 16:27:41'}, {'item': '斑点', 'pool': '标准寻访', 'time': '2025-9-11 16:27:32'}]\n",
      "[Warning] 无法纠正名称: \n",
      "[Warning] 无法纠正名称: \n",
      "[Warning] 无法纠正名称: 罗比车塔\n",
      "[Warning] 无法纠正名称: 未致蒙尘\n",
      "[Warning] 无法纠正名称: 障索\n",
      "[Warning] 无法纠正名称: 未致蒙尘\n",
      "[Warning] 无法纠正名称: 地有灵\n",
      "[Warning] 无法纠正名称: 未致蒙尘\n",
      "[Warning] 无法纠正名称: 寻澜\n",
      "[Warning] 无法纠正名称: 标准寻访\n",
      "[Warning] 无法纠正名称: 标准寻访\n",
      "[Warning] 无法纠正名称: 标准寻访\n",
      "[Warning] 无法纠正名称: 兰\n",
      "[Warning] 无法纠正名称: 标准寻访\n",
      "[Warning] 无法纠正名称: 验风\n",
      "[Warning] 无法纠正名称: 标准寻访\n",
      "[Warning] 无法纠正名称: 斑点\n",
      "[Warning] 无法纠正名称: 标准寻访\n",
      "已创建新文件: gacha_history\\arknights_20251224_151004.json\n",
      "找到 4 个历史文件\n",
      "其中 4 个文件与当前账号兼容（相同game_id、uid、timezone、lang）\n",
      "找到最新兼容文件: arknights_20251224_150729.json (导出时间: 2025-12-24 15:07:29)\n",
      "尝试合并: arknights_20251224_150729.json → arknights_20251224_151004.json\n",
      "合并完成，结果已保存到 gacha_history\\arknights_20251224_151004.json\n",
      "已删除旧文件: arknights_20251224_150729.json\n"
     ]
    }
   ],
   "source": [
    "# ===========================================================\n",
    "# 主程序入口\n",
    "# ===========================================================\n",
    "if __name__ == \"__main__\":\n",
    "    # 示例运行\n",
    "    image_source = \"./images\"\n",
    "    uid = \"679034235\"\n",
    "    timezone = 8\n",
    "    lang = \"zh-cn\"\n",
    "    \n",
    "    result_file = run_pipeline(image_source, uid, timezone, lang)\n",
    "    \n",
    "    if result_file:\n",
    "        print(f\"处理完成，结果保存在: {result_file}\")\n",
    "    else:\n",
    "        print(\"处理失败\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

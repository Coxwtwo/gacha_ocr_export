{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "64a63e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Union, Optional\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 设置 Tesseract 路径（Windows 用户）\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "# ===========================================================\n",
    "#  工具函数：读取配置文件\n",
    "# ===========================================================\n",
    "def load_config(config_path: str) -> Dict:\n",
    "    \"\"\"加载配置文件\"\"\"\n",
    "    with open(config_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# ===========================================================\n",
    "#  工具函数：裁剪表格区域\n",
    "# ===========================================================\n",
    "def crop_table_area(img: Image.Image, config: Dict) -> Image.Image:\n",
    "    \"\"\"根据配置文件中的比例裁剪表格区域\"\"\"\n",
    "    bounds = config[\"table_area\"][\"bounds\"]\n",
    "    w, h = img.size\n",
    "    left = int(w * bounds[\"left_ratio\"])\n",
    "    right = int(w * bounds[\"right_ratio\"])\n",
    "    top = int(h * bounds[\"top_ratio\"])\n",
    "    bottom = int(h * bounds[\"bottom_ratio\"])\n",
    "    return img.crop((left, top, right, bottom))\n",
    "\n",
    "# 明日方舟图片预处理\n",
    "def improve_for_arknights(img: Image.Image) -> Image.Image:\n",
    "    \"\"\"\n",
    "    对图片进行特定预处理以提高 OCR 准确率\n",
    "    \"\"\"    \n",
    "    im = img.copy()\n",
    "    img_array = np.array(im)\n",
    "    #　将特定颜色的像素（RGB(31,31,31)以及一定范围内相似的像素）设为黑色。\n",
    "    target_color = np.array([31, 31, 31])\n",
    "    tolerance = 15\n",
    "    \n",
    "    # 计算颜色差异\n",
    "    color_diff = np.abs(img_array[:, :, :3] - target_color)\n",
    "    mask = np.all(color_diff <= tolerance, axis=2)\n",
    "    \n",
    "    # 统一处理方式：无论图像模式如何，都只设置RGB通道为黑色\n",
    "    # 对于有alpha通道的图像，alpha通道保持不变\n",
    "    img_array[mask, :3] = [0, 0, 0]\n",
    "    # 返回处理后的 PIL.Image\n",
    "    processed_img = Image.fromarray(img_array)\n",
    "    return processed_img\n",
    "\n",
    "# ===========================================================\n",
    "#  工具函数：OCR 识别\n",
    "# ===========================================================\n",
    "def try_ocr(img: Image.Image, lang: str = \"chi_sim\") -> Optional[str]:\n",
    "    \"\"\"使用 pytesseract 对图片执行 OCR 并返回文本\"\"\"\n",
    "    try:\n",
    "        text = pytesseract.image_to_string(img, lang=lang)\n",
    "        print(f\"text: \\n{text}\")\n",
    "        return text.strip() if text else None\n",
    "    except Exception as e:\n",
    "        print(f\"[try_ocr] OCR 失败: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4c9d3f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================================\n",
    "#  工具函数：解析 OCR 文本\n",
    "# ===========================================================\n",
    "def parse_ocr_text(ocr_text: str, config: Dict) -> List[Dict]:\n",
    "    \"\"\"将 OCR 文本解析为结构化条目\"\"\"\n",
    "    if not ocr_text:\n",
    "        return []\n",
    "\n",
    "    column_indices = config[\"table_area\"][\"column_indices\"]\n",
    "    lines = [line.strip() for line in ocr_text.splitlines() if line.strip()]\n",
    "    entries = []\n",
    "\n",
    "    # 定义支持的日期格式正则表达式\n",
    "    date_patterns = [\n",
    "    r'(\\d{4}[-/]\\d{1,2}[-/]\\d{1,2}[ T]\\d{1,2}:\\d{2}:\\d{2})',  # 日期时间（带秒）\n",
    "    r'(\\d{4}[-/]\\d{1,2}[-/]\\d{1,2}[ T]\\d{1,2}:\\d{2})',        # 日期时间（不带秒）\n",
    "    r'(\\d{4}[-/]\\d{1,2}[-/]\\d{1,2})',                         # 日期（不带时间）\n",
    "    ]\n",
    "\n",
    "    for line in lines:\n",
    "        ts_match = None\n",
    "        for pattern in date_patterns:\n",
    "            ts_match = re.search(pattern, line)\n",
    "            if ts_match:\n",
    "                break  # 找到匹配的日期格式后退出循环\n",
    "\n",
    "        if ts_match:\n",
    "            ts = ts_match.group(1)\n",
    "            left_part = line[:ts_match.start()].strip(\" |,-\\t\")\n",
    "\n",
    "            # 优先尝试用竖线分割，如果没有竖线，再按多个连续空格分割\n",
    "            if \"|\" in left_part:\n",
    "                parts = [p.strip() for p in left_part.split(\"|\")]\n",
    "            else:\n",
    "                parts = re.split(r\"\\s{2,}\", left_part)\n",
    "\n",
    "            item = parts[column_indices[\"item\"]].strip() if len(parts) > column_indices[\"item\"] else \"\"\n",
    "            pool = parts[column_indices[\"pool\"]].strip() if len(parts) > column_indices[\"pool\"] else \"\"\n",
    "\n",
    "            entries.append({\"item\": item, \"pool\": pool, \"time\": ts})\n",
    "    print(f\"entries: {entries}\")\n",
    "    return entries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "04a11a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================================\n",
    "#  工具函数：修复时间\n",
    "# ===========================================================\n",
    "def fix_timestamp(ts: str) -> Optional[str]:\n",
    "    \"\"\"修复时间格式\"\"\"\n",
    "    if not ts:\n",
    "        return None\n",
    "\n",
    "    s = ts.strip().replace(\"T\", \" \").replace(\".\", \"-\").replace(\"/\", \"-\")\n",
    "    s = re.sub(r'[年月日]', '-', s)\n",
    "    s = re.sub(r'[^0-9\\- :]', '', s)\n",
    "\n",
    "    candidates = [\n",
    "        \"%Y-%m-%d %H:%M:%S\", \"%Y-%m-%d %H:%M\", \"%Y-%m-%d\",\n",
    "        \"%Y%m%d %H%M%S\", \"%Y%m%d%H%M%S\"\n",
    "    ]\n",
    "\n",
    "    for fmt in candidates:\n",
    "        try:\n",
    "            dt = datetime.strptime(s, fmt)\n",
    "            return dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    digits = re.sub(r'\\D', '', s)\n",
    "    if len(digits) >= 14:\n",
    "        try:\n",
    "            dt = datetime.strptime(digits[:14], \"%Y%m%d%H%M%S\")\n",
    "            return dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        except:\n",
    "            pass\n",
    "    elif len(digits) >= 8:\n",
    "        try:\n",
    "            dt = datetime.strptime(digits[:8], \"%Y%m%d\")\n",
    "            return dt.strftime(\"%Y-%m-%d 00:00:00\")\n",
    "        except:\n",
    "            pass\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "934778fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================================\n",
    "#  工具函数：纠正名称\n",
    "# ===========================================================\n",
    "def correct_name(name: str, valid_names: set) -> Dict[str, Union[str, bool]]:\n",
    "    \"\"\"纠正识别错误的名称\"\"\"\n",
    "    if name in valid_names:\n",
    "        return {\"name\": name, \"is_valid\": True}\n",
    "\n",
    "    def edit_distance(s1: str, s2: str) -> int:\n",
    "        if len(s1) < len(s2):\n",
    "            return edit_distance(s2, s1)\n",
    "        if len(s2) == 0:\n",
    "            return len(s1)\n",
    "\n",
    "        previous_row = range(len(s2) + 1)\n",
    "        for i, c1 in enumerate(s1):\n",
    "            current_row = [i + 1]\n",
    "            for j, c2 in enumerate(s2):\n",
    "                insertions = previous_row[j + 1] + 1\n",
    "                deletions = current_row[j] + 1\n",
    "                substitutions = previous_row[j] + (c1 != c2)\n",
    "                current_row.append(min(insertions, deletions, substitutions))\n",
    "            previous_row = current_row\n",
    "\n",
    "        return previous_row[-1]\n",
    "\n",
    "    best_match = min(valid_names, key=lambda x: edit_distance(name, x))\n",
    "    if edit_distance(name, best_match) <= len(name) // 2:\n",
    "        return {\"name\": best_match, \"is_valid\": True}\n",
    "\n",
    "    # 如果无法纠正，返回原始名称和无效标识\n",
    "    print(f\"[Warning] 无法纠正名称: {name}\")\n",
    "    return {\"name\": name, \"is_valid\": False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "68439f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================================\n",
    "#  工具函数：清理名称前后缀\n",
    "# ===========================================================\n",
    "def clean_name(name: str, prefix_patterns: List[str], suffix_patterns: List[str]) -> str:\n",
    "    \"\"\"\n",
    "    清理名称中的前缀和后缀。\n",
    "    :param name: 原始名称\n",
    "    :param prefix_patterns: 前缀的正则表达式列表\n",
    "    :param suffix_patterns: 后缀的正则表达式列表\n",
    "    :return: 清理后的名称\n",
    "    \"\"\"\n",
    "    for pattern in prefix_patterns:\n",
    "        name = re.sub(pattern, \"\", name).strip()\n",
    "    for pattern in suffix_patterns:\n",
    "        name = re.sub(pattern, \"\", name).strip()\n",
    "    return name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c09dfc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(file_path: str) -> Dict:\n",
    "    \"\"\"加载 JSON 文件\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def save_json(data: Dict, file_path: str):\n",
    "    \"\"\"保存 JSON 文件\"\"\"\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "def check_info(info1: Dict, info2: Dict) -> bool:\n",
    "    \"\"\"检查 info 字段是否一致\"\"\"\n",
    "    keys_to_check = ['game_id', 'uid', 'timezone', 'lang']\n",
    "    for key in keys_to_check:\n",
    "        if info1[key] != info2[key]:\n",
    "            print(f\"[Warning] 文件的 info 字段 {key} 不一致：{info1[key]} vs {info2[key]}\")\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def find_overlap(data1: List[Dict], data2: List[Dict]):\n",
    "    \"\"\"寻找重合条目，返回重合部分的起始和结束索引\"\"\"\n",
    "    for i in range(len(data1)):\n",
    "        for j in range(len(data2)):\n",
    "            if data1[i]['time'] == data2[j]['time'] and \\\n",
    "               data1[i]['pool'] == data2[j]['pool'] and \\\n",
    "               data1[i]['item'] == data2[j]['item']:\n",
    "                # 检查是否有连续的重合条目\n",
    "                k = 0\n",
    "                while i + k < len(data1) and j + k < len(data2) and \\\n",
    "                      data1[i + k]['time'] == data2[j + k]['time'] and \\\n",
    "                      data1[i + k]['pool'] == data2[j + k]['pool'] and \\\n",
    "                      data1[i + k]['item'] == data2[j + k]['item']:\n",
    "                    k += 1\n",
    "                if k >= 5:  # 找到连续 5 条以上的重合条目\n",
    "                    return i, i + k, j, j + k\n",
    "    return -1, -1, -1, -1\n",
    "\n",
    "def merge_data(data1: List[Dict], data2: List[Dict], overlap_start1: int, overlap_end1: int, overlap_start2: int, overlap_end2: int) -> List[Dict]:\n",
    "    \"\"\"合并数据，保留较长的重合前后部分\"\"\"\n",
    "    # 分割数据\n",
    "    before_overlap1 = data1[:overlap_start1]\n",
    "    overlap = data1[overlap_start1:overlap_end1]\n",
    "    after_overlap1 = data1[overlap_end1:]\n",
    "\n",
    "    before_overlap2 = data2[:overlap_start2]\n",
    "    after_overlap2 = data2[overlap_end2:]\n",
    "\n",
    "    # 比较重合前后的部分长度，保留较长的部分\n",
    "    before_overlap = before_overlap1 if len(before_overlap1) > len(before_overlap2) else before_overlap2\n",
    "    after_overlap = after_overlap1 if len(after_overlap1) > len(after_overlap2) else after_overlap2\n",
    "\n",
    "    # 合并数据\n",
    "    merged = before_overlap + overlap + after_overlap\n",
    "    return merged\n",
    "\n",
    "def merge_json_files(file1: str, file2: str, output_file: str):\n",
    "    \"\"\"合并两个 JSON 文件中的 data 部分\"\"\"\n",
    "    json1 = load_json(file1)\n",
    "    json2 = load_json(file2)\n",
    "\n",
    "    # 检查 info 字段是否一致\n",
    "    if not check_info(json1['info'], json2['info']):\n",
    "        raise ValueError(\"两个文件的 info 字段不一致，无法合并\")\n",
    "\n",
    "    # 使用时间戳较晚的文件的 info 信息\n",
    "    info = json2['info'] if json2['info']['export_timestamp'] > json1['info']['export_timestamp'] else json1['info']\n",
    "\n",
    "    # 寻找重合条目\n",
    "    start1, end1, start2, end2 = find_overlap(json1['data'], json2['data'])\n",
    "    if start1 == -1:\n",
    "        raise ValueError(\"未找到连续 5 条以上的重合条目，无法合并\")\n",
    "\n",
    "    # 合并 data 部分\n",
    "    merged_data = merge_data(json1['data'], json2['data'], start1, end1, start2, end2)\n",
    "\n",
    "    # 构建合并后的 JSON 数据\n",
    "    merged_json = {\n",
    "        \"info\": info,  # 使用时间戳较晚的文件的 info 信息\n",
    "        \"data\": merged_data\n",
    "    }\n",
    "\n",
    "    # 保存合并后的 JSON 文件\n",
    "    save_json(merged_json, output_file)\n",
    "\n",
    "\n",
    "def find_compatible_old_files(new_file_path: Path, existing_files: List[Path]) -> List[Path]:\n",
    "    \"\"\"找到与新文件info字段兼容的旧文件列表\"\"\"\n",
    "    compatible_files = []\n",
    "    \n",
    "    try:\n",
    "        # 读取新文件的info信息\n",
    "        with open(new_file_path, 'r', encoding='utf-8') as f:\n",
    "            new_data = json.load(f)\n",
    "        new_info = new_data['info']\n",
    "        \n",
    "        for file_path in existing_files:\n",
    "            try:\n",
    "                # 读取旧文件的info信息\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    old_data = json.load(f)\n",
    "                old_info = old_data['info']\n",
    "                \n",
    "                # 检查关键字段是否一致\n",
    "                if (new_info['game_id'] == old_info['game_id'] and\n",
    "                    new_info['uid'] == old_info['uid'] and\n",
    "                    new_info['timezone'] == old_info['timezone'] and\n",
    "                    new_info['lang'] == old_info['lang']):\n",
    "                    compatible_files.append(file_path)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"读取文件 {file_path} 失败: {e}\")\n",
    "                continue\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"读取新文件 {new_file_path} 失败: {e}\")\n",
    "    \n",
    "    return compatible_files\n",
    "\n",
    "def get_latest_file_by_export_timestamp(files: List[Path]) -> tuple[Optional[Path], int]:\n",
    "    \"\"\"根据export_timestamp找到时间戳最晚的文件\"\"\"\n",
    "    if not files:\n",
    "        return None\n",
    "    \n",
    "    latest_file = None\n",
    "    latest_timestamp = 0\n",
    "    \n",
    "    for file_path in files:\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "            timestamp = data['info']['export_timestamp']\n",
    "            \n",
    "            if timestamp > latest_timestamp:\n",
    "                latest_timestamp = timestamp\n",
    "                latest_file = file_path\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"读取文件 {file_path} 失败: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return latest_file, latest_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c0da0701",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(\n",
    "    image_source: Union[str, List[str]],\n",
    "    uid: str = \"1234567890\",\n",
    "    timezone: int = 8,\n",
    "    lang: str = \"zh-cn\",\n",
    "):\n",
    "    \"\"\"主流程：OCR → 解析 → 名称修正 → 导出 → 合并\"\"\"\n",
    "    config = load_config(\"game_processing_config_ark.json\")\n",
    "    game_data = load_config(\"game_name_ark.json\")\n",
    "    game_id = config[\"game_info\"][\"game_id\"]\n",
    "    game_name = config[\"game_info\"][\"game_name\"]\n",
    "\n",
    "    # 构建有效名称集合\n",
    "    valid_items = set(game_data[\"character\"])  # 角色名称\n",
    "    valid_pools = set(game_data[\"pool\"])  # 卡池名称\n",
    "\n",
    "    # 是否启用前后缀清理模块\n",
    "    enable_clean_name = config[\"text_processing\"][\"enable_clean_name\"]\n",
    "    prefix_patterns = config[\"text_processing\"][\"patterns\"][\"prefix_patterns\"]\n",
    "    suffix_patterns = config[\"text_processing\"][\"patterns\"][\"suffix_patterns\"]\n",
    "\n",
    "    if isinstance(image_source, str) and Path(image_source).is_dir():\n",
    "        image_paths = [str(p) for p in Path(image_source).rglob(\"*.png\")]\n",
    "    else:\n",
    "        image_paths = list(image_source)\n",
    "\n",
    "    # 获取当前时间戳\n",
    "    export_timestamp = int(datetime.now().timestamp())\n",
    "    export_time_str = datetime.fromtimestamp(export_timestamp).strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    all_entries = []\n",
    "\n",
    "    for path in image_paths:\n",
    "        img = Image.open(path)\n",
    "        cropped_img = crop_table_area(img, config)\n",
    "        cropped_img = improve_for_arknights(cropped_img)\n",
    "        ocr_text = try_ocr(cropped_img)\n",
    "        entries = parse_ocr_text(ocr_text, config)\n",
    "\n",
    "        for entry in entries:\n",
    "            # 清理名称（如果启用）\n",
    "            if enable_clean_name:\n",
    "                entry[\"item\"] = clean_name(\n",
    "                    entry[\"item\"], prefix_patterns, suffix_patterns\n",
    "                )\n",
    "                entry[\"pool\"] = clean_name(\n",
    "                    entry[\"pool\"], prefix_patterns, suffix_patterns\n",
    "                )\n",
    "\n",
    "            # 纠正名称\n",
    "            item_result = correct_name(entry[\"item\"], valid_items)\n",
    "            pool_result = correct_name(entry[\"pool\"], valid_pools)\n",
    "\n",
    "            entry[\"item\"] = item_result[\"name\"]\n",
    "            entry[\"pool\"] = pool_result[\"name\"]\n",
    "            entry[\"is_valid\"] = item_result[\"is_valid\"] and pool_result[\"is_valid\"]\n",
    "\n",
    "            # 修复时间\n",
    "            entry[\"time\"] = fix_timestamp(entry[\"time\"])\n",
    "\n",
    "        all_entries.extend(entries)\n",
    "\n",
    "    # 对 data 部分按 time 排序\n",
    "    all_entries.sort(key=lambda x: x[\"time\"], reverse=True)\n",
    "\n",
    "    # 构建导出信息\n",
    "    export_data = {\n",
    "        \"info\": {\n",
    "            \"game_id\": game_id,\n",
    "            \"game_name\": game_name,\n",
    "            \"export_timestamp\": export_timestamp,\n",
    "            \"export_app\": \"ocr_export\",\n",
    "            \"export_app_version\": \"v0.0.1\",\n",
    "            \"export_time\": datetime.fromtimestamp(export_timestamp).strftime(\n",
    "                \"%Y-%m-%d %H:%M:%S\"\n",
    "            ),\n",
    "            \"uid\": uid,\n",
    "            \"timezone\": timezone,\n",
    "            \"lang\": lang,\n",
    "            \"total_entries\": len(all_entries),\n",
    "        },\n",
    "        \"data\": all_entries,\n",
    "    }\n",
    "    output_folder = Path(\"gacha_history\")  # 指定输出文件夹\n",
    "    output_folder.mkdir(exist_ok=True)  # 如果文件夹不存在则创建\n",
    "    output_file = output_folder / f\"{game_id}_{export_time_str}.json\"\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(export_data, f, ensure_ascii=False, indent=4)\n",
    "    print(f\"已创建新文件: {output_file}\")\n",
    "\n",
    "    # 检查是否存在以 game_id 开头的文件（配置中的game_id）\n",
    "    existing_files = list(output_folder.glob(f\"{game_id}_*.json\"))\n",
    "    # 排除当前刚创建的文件\n",
    "    existing_files = [f for f in existing_files if f != output_file]\n",
    "    \n",
    "    if existing_files:\n",
    "        print(f\"找到 {len(existing_files)} 个历史文件\")\n",
    "        \n",
    "        # 1. 找到与新文件兼容的旧文件\n",
    "        compatible_files = find_compatible_old_files(output_file, existing_files)\n",
    "        print(f\"其中 {len(compatible_files)} 个文件与当前账号兼容（相同game_id、uid、timezone、lang）\")\n",
    "        \n",
    "        if compatible_files:\n",
    "            # 2. 用时间戳最晚的旧文件与新文件合并\n",
    "            latest_file, latest_timestamp = get_latest_file_by_export_timestamp(compatible_files)\n",
    "            \n",
    "            if latest_file:\n",
    "                print(f\"找到最新兼容文件: {latest_file.name} (导出时间: {datetime.fromtimestamp(latest_timestamp).strftime('%Y-%m-%d %H:%M:%S')})\")\n",
    "                \n",
    "                try:\n",
    "                    print(f\"尝试合并: {latest_file.name} → {output_file.name}\")\n",
    "                    merge_json_files(str(latest_file), str(output_file), str(output_file))\n",
    "                except ValueError as e:\n",
    "                    print(f\"合并失败: {e}\")\n",
    "                    print(f\"保留两个独立文件: {latest_file.name} 和 {output_file.name}\")\n",
    "                else:\n",
    "                    print(f\"合并完成，结果已保存到 {output_file}\")\n",
    "                    \n",
    "                    # 删除被合并的旧文件\n",
    "                    try:\n",
    "                        latest_file.unlink()\n",
    "                        print(f\"已删除旧文件: {latest_file.name}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"警告：无法删除旧文件 {latest_file.name}: {e}\")\n",
    "            else:\n",
    "                print(\"未找到有效的兼容文件进行合并\")\n",
    "        else:\n",
    "            print(\"未找到兼容的历史文件，可能是不同账号的记录，保留独立文件\")\n",
    "    else:\n",
    "        print(f\"未找到历史文件，无需合并，保存文件 {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f3170e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: \n",
      "以风雪为拆                                  香草                         2025-11-14 11:43:46\n",
      "以风雪为拆                                    芬                          2025-11-13 11:34:56\n",
      "以风雪为拆                                  酸糖                         2025-11-12 10:37:07\n",
      "以风雪为拆                                  验风                         2025-11-11 10:49:29\n",
      "以风雪为拆                                  古米                         2025-11-10 10:56:13\n",
      "以风雪为拆                                 月见夜                       2025-11-10 10:56:13\n",
      "以风雪为拆                                  露托                         2025-11-10 10:56:13\n",
      "以风雪为拆                                  空爆                         2025-11-10 10:56:13\n",
      "以风雪为拆                                 调香师                       2025-11-10 10:56:13\n",
      "以风雪为拆                                  卡强                         2025-11-10 10:56:13\n",
      "\n",
      "\n",
      "entries: [{'item': '香草', 'pool': '以风雪为拆', 'time': '2025-11-14 11:43:46'}, {'item': '芬', 'pool': '以风雪为拆', 'time': '2025-11-13 11:34:56'}, {'item': '酸糖', 'pool': '以风雪为拆', 'time': '2025-11-12 10:37:07'}, {'item': '验风', 'pool': '以风雪为拆', 'time': '2025-11-11 10:49:29'}, {'item': '古米', 'pool': '以风雪为拆', 'time': '2025-11-10 10:56:13'}, {'item': '月见夜', 'pool': '以风雪为拆', 'time': '2025-11-10 10:56:13'}, {'item': '露托', 'pool': '以风雪为拆', 'time': '2025-11-10 10:56:13'}, {'item': '空爆', 'pool': '以风雪为拆', 'time': '2025-11-10 10:56:13'}, {'item': '调香师', 'pool': '以风雪为拆', 'time': '2025-11-10 10:56:13'}, {'item': '卡强', 'pool': '以风雪为拆', 'time': '2025-11-10 10:56:13'}]\n",
      "[Warning] 无法纠正名称: 验风\n",
      "text: \n",
      "空白频段                                    空爆                         2025-10-9 12:00:10\n",
      "空白频段                                  米格鲁                        2025-10-9 12:00:10\n",
      "空白频段                                  休谋斯                        2025-10-9 12:00:10\n",
      "空白频段                                  玫兰莎                        2025-10-9 12:00:10\n",
      "空白频段                                    杜宾                         2025-10-9 11:59:53\n",
      "空白频段                                    空爆                         2025-10-9 11:59:53\n",
      "空白频段                         过NEWI折本                         2025-10-9 11:59:53\n",
      "空白频段                         洁NEWI冬时                         2025-10-9 11:59:53\n",
      "空白频段                                    验风                         2025-10-9 11:59:53\n",
      "空白频段                                  清道夫                        2025-10-9 11:59:53\n",
      "\n",
      "\n",
      "entries: [{'item': '空爆', 'pool': '空白频段', 'time': '2025-10-9 12:00:10'}, {'item': '米格鲁', 'pool': '空白频段', 'time': '2025-10-9 12:00:10'}, {'item': '休谋斯', 'pool': '空白频段', 'time': '2025-10-9 12:00:10'}, {'item': '玫兰莎', 'pool': '空白频段', 'time': '2025-10-9 12:00:10'}, {'item': '杜宾', 'pool': '空白频段', 'time': '2025-10-9 11:59:53'}, {'item': '空爆', 'pool': '空白频段', 'time': '2025-10-9 11:59:53'}, {'item': '过NEWI折本', 'pool': '空白频段', 'time': '2025-10-9 11:59:53'}, {'item': '洁NEWI冬时', 'pool': '空白频段', 'time': '2025-10-9 11:59:53'}, {'item': '验风', 'pool': '空白频段', 'time': '2025-10-9 11:59:53'}, {'item': '清道夫', 'pool': '空白频段', 'time': '2025-10-9 11:59:53'}]\n",
      "[Warning] 无法纠正名称: 休谋斯\n",
      "[Warning] 无法纠正名称: 过I折本\n",
      "[Warning] 无法纠正名称: 验风\n",
      "text: \n",
      "空白频段                                    冬时                         2025-10-9 12:00:17\n",
      "空白频段                                  米格鲁                        2025-10-9 12:00:17\n",
      "空白频段                      二NEWI真言 (6太)                      2025-10-9 12:00:17\n",
      "空白频段                                    倒羽                          2025-10-9 12:00:17\n",
      "空白频段                                    流星                         2025-10-9 12:00:10\n",
      "空白频段                                    松果                         2025-10-9 12:00:10\n",
      "空白频段                                    渡桥                         2025-10-9 12:00:10\n",
      "空白频段                                    铀躁                         2025-10-9 12:00:10\n",
      "空白频段                                    露托                         2025-10-9 12:00:10\n",
      "空白频段                                    空爆                         2025-10-9 12:00:10\n",
      "\n",
      "\n",
      "entries: [{'item': '冬时', 'pool': '空白频段', 'time': '2025-10-9 12:00:17'}, {'item': '米格鲁', 'pool': '空白频段', 'time': '2025-10-9 12:00:17'}, {'item': '二NEWI真言 (6太)', 'pool': '空白频段', 'time': '2025-10-9 12:00:17'}, {'item': '倒羽', 'pool': '空白频段', 'time': '2025-10-9 12:00:17'}, {'item': '流星', 'pool': '空白频段', 'time': '2025-10-9 12:00:10'}, {'item': '松果', 'pool': '空白频段', 'time': '2025-10-9 12:00:10'}, {'item': '渡桥', 'pool': '空白频段', 'time': '2025-10-9 12:00:10'}, {'item': '铀躁', 'pool': '空白频段', 'time': '2025-10-9 12:00:10'}, {'item': '露托', 'pool': '空白频段', 'time': '2025-10-9 12:00:10'}, {'item': '空爆', 'pool': '空白频段', 'time': '2025-10-9 12:00:10'}]\n",
      "[Warning] 无法纠正名称: 倒羽\n",
      "[Warning] 无法纠正名称: 铀躁\n",
      "text: \n",
      "未致蒙尘\n",
      "\n",
      "2025-9-20 10:34:53\n",
      "\n",
      "未致蒙尘                                 罗比车塔                       2025-9-20 10:34:48\n",
      "未致蒙尘                                          障索                              2025-9-20 09:12:22\n",
      "未致蒙尘                                          地有灵                              2025-9-20 09:12:16\n",
      "标准寻访                                    寻澜                         2025-9-11 16:28:00\n",
      "标准寻访                                    古米                         2025-9-11 16:27:55\n",
      "标准寻访                                     芬                           2025-9-11 16:27:51\n",
      "标准寻访                                      兰                         2025-9-11 16:27:47\n",
      "标准寻访                                    验风                         2025-9-11 16:27:41\n",
      "标准寻访                                    斑点                         2025-9-11 16:27:32\n",
      "\n",
      "\n",
      "entries: [{'item': '', 'pool': '', 'time': '2025-9-20 10:34:53'}, {'item': '罗比车塔', 'pool': '未致蒙尘', 'time': '2025-9-20 10:34:48'}, {'item': '障索', 'pool': '未致蒙尘', 'time': '2025-9-20 09:12:22'}, {'item': '地有灵', 'pool': '未致蒙尘', 'time': '2025-9-20 09:12:16'}, {'item': '寻澜', 'pool': '标准寻访', 'time': '2025-9-11 16:28:00'}, {'item': '古米', 'pool': '标准寻访', 'time': '2025-9-11 16:27:55'}, {'item': '芬', 'pool': '标准寻访', 'time': '2025-9-11 16:27:51'}, {'item': '兰', 'pool': '标准寻访', 'time': '2025-9-11 16:27:47'}, {'item': '验风', 'pool': '标准寻访', 'time': '2025-9-11 16:27:41'}, {'item': '斑点', 'pool': '标准寻访', 'time': '2025-9-11 16:27:32'}]\n",
      "[Warning] 无法纠正名称: \n",
      "[Warning] 无法纠正名称: \n",
      "[Warning] 无法纠正名称: 罗比车塔\n",
      "[Warning] 无法纠正名称: 未致蒙尘\n",
      "[Warning] 无法纠正名称: 障索\n",
      "[Warning] 无法纠正名称: 未致蒙尘\n",
      "[Warning] 无法纠正名称: 地有灵\n",
      "[Warning] 无法纠正名称: 未致蒙尘\n",
      "[Warning] 无法纠正名称: 寻澜\n",
      "[Warning] 无法纠正名称: 标准寻访\n",
      "[Warning] 无法纠正名称: 标准寻访\n",
      "[Warning] 无法纠正名称: 标准寻访\n",
      "[Warning] 无法纠正名称: 兰\n",
      "[Warning] 无法纠正名称: 标准寻访\n",
      "[Warning] 无法纠正名称: 验风\n",
      "[Warning] 无法纠正名称: 标准寻访\n",
      "[Warning] 无法纠正名称: 斑点\n",
      "[Warning] 无法纠正名称: 标准寻访\n",
      "已创建新文件: gacha_history\\arknights_20251224_151004.json\n",
      "找到 4 个历史文件\n",
      "其中 4 个文件与当前账号兼容（相同game_id、uid、timezone、lang）\n",
      "找到最新兼容文件: arknights_20251224_150729.json (导出时间: 2025-12-24 15:07:29)\n",
      "尝试合并: arknights_20251224_150729.json → arknights_20251224_151004.json\n",
      "合并完成，结果已保存到 gacha_history\\arknights_20251224_151004.json\n",
      "已删除旧文件: arknights_20251224_150729.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 示例运行\n",
    "if __name__ == \"__main__\":\n",
    "    image_source = \"./images\"\n",
    "    uid = \"679034235\"\n",
    "    timezone = 8\n",
    "    lang = \"zh-cn\"\n",
    "    run_pipeline(image_source, uid, timezone, lang)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
